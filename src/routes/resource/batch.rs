use axum::{
    extract::{Extension, Path},
    http::HeaderMap,
};
use tracing::info;

use crate::error::DfsError;
use crate::modules::network::RealConnectInfo;
use crate::record_request_metrics;
use crate::responses::ErrorResponse;
use crate::{container::AppContext, modules::external::geolocation};

// é™æ€é…ç½®ï¼šæœ€å¤§å¹¶å‘Flowæ•°é‡
const MAX_CONCURRENT_FLOWS: usize = 4;

#[utoipa::path(
    post,
    path = "/session/{sessionid}/{resid}",
    tag = "Resource", 
    summary = "Get CDN URLs for multiple file chunks",
    description = "Retrieves CDN URLs for downloading multiple chunks using an active session",
    request_body = crate::models::BatchChunkRequest,
    responses(
        (status = 200, description = "CDN URLs generated successfully", body = crate::responses::BatchCdnUrlResponse),
        (status = 400, description = "Invalid request parameters", body = ErrorResponse),
        (status = 404, description = "Session or resource not found", body = ErrorResponse),
        (status = 429, description = "Too many download attempts", body = ErrorResponse),
        (status = 500, description = "Internal server error", body = ErrorResponse)
    )
)]
pub async fn post_batch_cdn(
    Extension(ctx): Extension<AppContext>,
    Extension(real_connect_info): Extension<RealConnectInfo>,
    headers: HeaderMap,
    Path((sessionid, resid)): Path<(String, String)>,
    axum::Json(payload): axum::Json<crate::models::BatchChunkRequest>,
) -> crate::error::DfsResult<crate::responses::ApiResponse> {
    let start_time = std::time::Instant::now();

    // éªŒè¯è¾“å…¥
    if payload.chunks.is_empty() {
        return Err(DfsError::invalid_input(
            "chunks",
            "Chunks array cannot be empty",
        ));
    }
    if payload.chunks.len() > 100 {
        return Err(DfsError::invalid_input(
            "chunks",
            "Too many chunks requested (max 100)",
        ));
    }

    // æå–å®¢æˆ·ç«¯IP
    let client_ip = crate::modules::external::geolocation::extract_client_ip(&headers)
        .or_else(|| Some(real_connect_info.remote_addr.ip()));

    // é¢„å…ˆè®¡ç®—IPå­—ç¬¦ä¸²å’Œåœ°ç†ä½ç½®ä¿¡æ¯ï¼ˆé¿å…åœ¨æ¯ä¸ªchunkä¸­é‡å¤è®¡ç®—ï¼‰
    let client_ip_str = if let Some(ip) = client_ip {
        ip.to_string()
    } else {
        "unknown".to_string()
    };
    let client_geo_str = if let Some(ip) = client_ip {
        geolocation::get_ip_location_data(ip).unwrap_or("unknown".to_string())
    } else {
        "unknown".to_string()
    };

    // 1. ä¸€æ¬¡æ€§éªŒè¯sessionå’Œèµ„æºï¼ˆå…±äº«ï¼‰
    let session = ctx
        .session_service
        .get_validated_session(&sessionid)
        .await?;
    let config_guard = ctx.shared_config.load();
    let resource = config_guard
        .get_resource(&resid)
        .ok_or_else(|| DfsError::resource_not_found(&resid))?;

    // 2. Pipelineæ‰¹é‡è¯»å–æ‰€æœ‰chunkä¿¡æ¯
    let batch_data = ctx
        .data_store
        .batch_check_and_increment_downloads(&sessionid, &payload.chunks)
        .await
        .map_err(|e| DfsError::internal_error(format!("Batch Redis read failed: {}", e)))?;

    // 3. éªŒè¯ä¸‹è½½é™åˆ¶
    for (chunk, count) in &batch_data.valid_chunks {
        if *count > 3 {
            // MAX_CHUNK_DOWNLOADS
            return Err(DfsError::invalid_input(
                "download_count",
                &format!("Too many download attempts for chunk: {}", chunk),
            ));
        }
    }

    // 4. é™åˆ¶å¹¶å‘Flowæ‰§è¡Œï¼ˆå…³é”®ï¼šé™åˆ¶ä¸º4ä¸ªï¼‰
    let semaphore = std::sync::Arc::new(tokio::sync::Semaphore::new(MAX_CONCURRENT_FLOWS));
    let batch_data = std::sync::Arc::new(batch_data); // ä½¿ç”¨Arcæ¥å…±äº«æ•°æ®
    let tasks_with_chunk_ids: Vec<_> = payload
        .chunks
        .into_iter()
        .map(|chunk_range| {
            let original_chunk_id = chunk_range.clone(); // ä¿å­˜åŸå§‹chunk_id
            let ctx = ctx.clone();
            let session = session.clone();
            let resource = resource.clone();
            let batch_data_ref = batch_data.clone();
            let semaphore = semaphore.clone();

            let task = tokio::spawn(async move {
                let _permit = semaphore.acquire().await.unwrap();

                process_chunk_with_preloaded_data(
                    &ctx,
                    &session,
                    &chunk_range,
                    &resource,
                    &*batch_data_ref,
                    client_ip,
                )
                .await
            });
            
            (original_chunk_id, task) // è¿”å›(chunk_id, task)å…ƒç»„
        })
        .collect();

    // 5. æ”¶é›†æ‰€æœ‰ç»“æœ
    let mut chunk_results = std::collections::HashMap::new();
    let mut cdn_records_to_store = Vec::new();
    let mut server_bandwidth_map = std::collections::HashMap::new();
    let mut total_bandwidth = 0u64;

    for (original_chunk_id, task) in tasks_with_chunk_ids {
        let result = task
            .await
            .map_err(|e| DfsError::internal_error(format!("Task execution failed: {}", e)))?;

        match result {
            Ok(chunk_result) => {
                chunk_results.insert(
                    chunk_result.chunk_id.clone(),
                    crate::responses::ChunkResult {
                        url: chunk_result.url,
                        error: None,
                    },
                );

                // å…ˆè·å–weightç”¨äºæ—¥å¿—è®°å½•
                let weight = chunk_result
                    .cdn_record
                    .as_ref()
                    .map(|r| r.weight)
                    .unwrap_or(0);

                // æ”¶é›†CDNè®°å½•å’Œå¸¦å®½ä¿¡æ¯
                if let Some(cdn_record) = chunk_result.cdn_record {
                    cdn_records_to_store.push(
                        crate::modules::storage::data_store::BatchCdnRecord {
                            chunk_id: chunk_result.chunk_id.clone(),
                            record: cdn_record,
                        },
                    );
                }

                if let Some(bandwidth_info) = chunk_result.bandwidth_info {
                    if let Some(server_id) = bandwidth_info.server_id {
                        *server_bandwidth_map.entry(server_id.clone()).or_default() +=
                            bandwidth_info.bytes;
                        total_bandwidth += bandwidth_info.bytes;

                        // QPS metricsè®°å½• (çº¯å†…å­˜æ“ä½œ)
                        ctx.metrics
                            .record_scheduled_request(&resid, &server_id, false);

                        // æ¯ä¸ªchunkçš„ç‹¬ç«‹è°ƒåº¦æ—¥å¿—
                        let chunk_size_mb = bandwidth_info.bytes as f64 / 1024.0 / 1024.0;

                        info!(
                            "{}/{} size={:.2}MB -> {} weight={} ip={} geo={}",
                            if let Some(ref sub_path_val) = session.sub_path {
                                format!("{resid}/{sub_path_val}")
                            } else {
                                resid.clone()
                            },
                            chunk_result.chunk_id,
                            chunk_size_mb,
                            server_id,
                            weight,
                            client_ip_str,
                            client_geo_str
                        );
                    }
                }
            }
            Err(e) => {
                // è®¡ç®—èµ„æºè·¯å¾„å’Œæ–‡ä»¶å¤§å°ç”¨äºæ—¥å¿—è®°å½•
                let resource_path = if let Some(ref sub_path_val) = session.sub_path {
                    format!("{}/{}", resid, sub_path_val)
                } else {
                    resid.clone()
                };
                
                // å°è¯•è§£æchunkèŒƒå›´ä»¥è®¡ç®—æ–‡ä»¶å¤§å°
                let file_size_mb = if let Ok(ranges) = parse_and_validate_ranges(&original_chunk_id) {
                    calculate_file_size_from_ranges(&ranges) as f64 / (1024.0 * 1024.0)
                } else {
                    0.0
                };

                // è®°å½•é”™è¯¯æ—¥å¿—ï¼ˆä¸å•ä¸ªCDNè·å–ä¿æŒä¸€è‡´çš„æ ¼å¼ï¼‰
                tracing::error!(
                    "BATCH-ERROR {} chunk={} size={:.2}MB {}",
                    resource_path, original_chunk_id, file_size_mb, e
                );

                // ä½¿ç”¨åŸå§‹chunk_idè€Œä¸æ˜¯ç”Ÿæˆè™šå‡çš„chunk_id
                chunk_results.insert(
                    original_chunk_id,
                    crate::responses::ChunkResult {
                        url: None,
                        error: Some(e.to_string()),
                    },
                );
            }
        }
    }

    // 6. Pipelineæ‰¹é‡å†™å…¥CDNè®°å½•å’Œå¸¦å®½ç»Ÿè®¡
    if !cdn_records_to_store.is_empty() || total_bandwidth > 0 {
        // å…‹éš†server_bandwidth_mapç”¨äºåˆ†é’Ÿçº§æµé‡ç»Ÿè®¡
        let server_bandwidth_for_minute = server_bandwidth_map.clone();

        let bandwidth_batch = crate::modules::storage::data_store::MultiBandwidthUpdateBatch {
            resource_id: resid.clone(),
            server_updates: server_bandwidth_map,
            total_bytes: total_bandwidth,
        };

        ctx.data_store
            .batch_write_cdn_and_bandwidth(&sessionid, &cdn_records_to_store, &bandwidth_batch)
            .await
            .map_err(|e| DfsError::internal_error(format!("Batch Redis write failed: {}", e)))?;

        // 7. è®°å½•åˆ†é’Ÿçº§æµé‡ç»Ÿè®¡ (å†…å­˜ç¼“å­˜ï¼Œå®šæœŸæ‰¹é‡å†™Redis)
        for (server_id, bytes) in &server_bandwidth_for_minute {
            ctx.bandwidth_cache_service
                .record_bandwidth(server_id, *bytes)
                .await;
        }
    }

    // 8. è®°å½•æ€»ä½“æŒ‡æ ‡
    record_request_metrics!(ctx.metrics, start_time);

    Ok(crate::responses::ApiResponse::success(
        crate::responses::ResponseData::BatchCdn(crate::responses::BatchCdnUrlResponse {
            urls: chunk_results,
        }),
    ))
}

// å¤„ç†å•ä¸ªchunkï¼ˆä½¿ç”¨é¢„åŠ è½½çš„æ•°æ®ï¼‰
async fn process_chunk_with_preloaded_data(
    ctx: &AppContext,
    session: &crate::models::Session,
    chunk_range: &str,
    resource: &crate::config::ResourceConfig,
    batch_data: &crate::models::BatchChunkData,
    client_ip: Option<std::net::IpAddr>,
) -> crate::error::DfsResult<crate::models::ChunkProcessResult> {
    // æ£€æŸ¥chunkæ˜¯å¦æœ‰æ•ˆ
    if batch_data.invalid_chunks.contains(&chunk_range.to_string()) {
        return Err(DfsError::invalid_input("chunk", "Invalid chunk range"));
    }

    // è§£æranges
    let ranges = parse_and_validate_ranges(chunk_range)?;

    // è·å–é¢„åŠ è½½çš„penaltyæœåŠ¡å™¨
    let penalty_servers: Vec<String> = batch_data
        .cdn_records
        .get(chunk_range)
        .map(|records| {
            records
                .iter()
                .filter_map(|record| {
                    if !record.skip_penalty {
                        record.server_id.clone()
                    } else {
                        None
                    }
                })
                .collect()
        })
        .unwrap_or_default();

    // æ‰§è¡Œflowï¼ˆæ— Redisæ“ä½œï¼Œçº¯è®¡ç®—ï¼‰
    let file_size = Some(calculate_file_size_from_ranges(&ranges));
    let target = crate::models::FlowTarget {
        resource_id: session.resource_id.clone(),
        version: session.version.clone(),
        sub_path: session.sub_path.clone(),
        ranges: Some(ranges),
        file_size,
    };

    let context = crate::models::FlowContext {
        client_ip,
        session_id: Some(session.resource_id.clone()),
        extras: session.extras.clone(),
    };

    let options = crate::models::FlowOptions {
        cdn_full_range: false,
    };

    let flow_result = ctx
        .flow_service
        .execute_flow(&target, &context, &options, &resource.flow, penalty_servers, Some(session))
        .await?;

    // å‡†å¤‡CDNè®°å½•
    let cdn_record = crate::models::CdnRecord {
        url: flow_result.url.clone(),
        server_id: flow_result.selected_server_id.clone(),
        skip_penalty: false,
        timestamp: chrono::Utc::now().timestamp() as u64,
        weight: flow_result.selected_server_weight.unwrap_or(0),
        size: file_size,
    };

    // å‡†å¤‡å¸¦å®½ä¿¡æ¯
    let bandwidth_info =
        flow_result
            .selected_server_id
            .map(|server_id| crate::models::BandwidthInfo {
                server_id: Some(server_id),
                bytes: file_size.unwrap_or(0),
                chunk_id: chunk_range.to_string(),
            });

    Ok(crate::models::ChunkProcessResult {
        chunk_id: chunk_range.to_string(),
        url: Some(flow_result.url),
        error: None,
        bandwidth_info,
        cdn_record: Some(cdn_record),
    })
}

// è§£æå¹¶éªŒè¯ranges
fn parse_and_validate_ranges(range_str: &str) -> crate::error::DfsResult<Vec<(u32, u32)>> {
    let ranges = if range_str.contains(',') {
        // Multiple ranges: "0-255,256-511,512-767"
        let mut parsed_ranges = Vec::new();
        for range_part in range_str.split(',') {
            let range_part = range_part.trim();
            if let Some((start_str, end_str)) = range_part.split_once('-') {
                let start = start_str.parse::<u32>().map_err(|_| {
                    DfsError::invalid_input(
                        "range",
                        format!("Invalid range format in part: {range_part}"),
                    )
                })?;
                let end = end_str.parse::<u32>().map_err(|_| {
                    DfsError::invalid_input(
                        "range",
                        format!("Invalid range format in part: {range_part}"),
                    )
                })?;
                parsed_ranges.push((start, end));
            } else {
                return Err(DfsError::invalid_input(
                    "range",
                    format!("Invalid range format in part: {range_part}"),
                ));
            }
        }
        if parsed_ranges.is_empty() {
            return Err(DfsError::invalid_input("range", "No valid ranges found"));
        }
        parsed_ranges
    } else {
        // Single range: "0-255"
        if let Some((start_str, end_str)) = range_str.split_once('-') {
            let start = start_str
                .parse::<u32>()
                .map_err(|_| DfsError::invalid_input("range", "Invalid range format"))?;
            let end = end_str
                .parse::<u32>()
                .map_err(|_| DfsError::invalid_input("range", "Invalid range format"))?;
            vec![(start, end)]
        } else {
            return Err(DfsError::invalid_input("range", "Invalid range format"));
        }
    };

    Ok(ranges)
}

// è®¡ç®—rangesè¦†ç›–çš„å­—èŠ‚æ•°
fn calculate_file_size_from_ranges(ranges: &[(u32, u32)]) -> u64 {
    ranges
        .iter()
        .map(|(start, end)| (end - start + 1) as u64)
        .sum()
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::tests::common::*;
    use axum::http::{HeaderMap, StatusCode};
    // æ‰¹é‡CDN APIé›†æˆæµ‹è¯•
    #[tokio::test]
    async fn test_post_batch_cdn_success() {
        let env = TestEnvironment::new().await;

        // åˆ›å»ºæµ‹è¯•sessionï¼ŒåŒ…å«å¤šä¸ªchunks
        let session_id = "test_batch_session";
        let session = SessionBuilder::new()
            .with_resource_id("test_resource")
            .with_version("1.0.0")
            .with_chunks(vec!["0-1023", "1024-2047", "2048-4095"])
            .build();

        env.services
            .session_service
            .store_session(session_id, &session)
            .await
            .unwrap();

        // æ„é€ POSTè¯·æ±‚
        let request_body = crate::models::BatchChunkRequest {
            chunks: vec![
                "0-1023".to_string(),
                "1024-2047".to_string(),
                "2048-4095".to_string(),
            ],
        };

        // æ¨¡æ‹Ÿheaderså’Œè¿æ¥ä¿¡æ¯
        let headers = HeaderMap::new();
        let real_connect_info = RealConnectInfo::from_headers_and_addr(
            &HeaderMap::new(),
            "127.0.0.1:8080".parse().unwrap(),
        );

        // è°ƒç”¨æ‰¹é‡CDN API
        let response = post_batch_cdn(
            Extension(env.app_context.clone()),
            Extension(real_connect_info),
            headers,
            Path((session_id.to_string(), "test_resource".to_string())),
            axum::Json(request_body),
        )
        .await;

        // éªŒè¯å“åº”
        assert!(response.is_ok(), "APIåº”è¯¥æˆåŠŸå“åº”");

        let api_response = response.unwrap();
        let response = axum::response::IntoResponse::into_response(api_response);
        let (parts, body) = response.into_parts();

        // è§£æå“åº”ä½“éªŒè¯æ ¼å¼
        let body_bytes = axum::body::to_bytes(body, usize::MAX).await.unwrap();

        // å¦‚æœä¸æ˜¯200ï¼Œæ‰“å°å“åº”ä½“æ¥è°ƒè¯•
        if parts.status != StatusCode::OK {
            let body_str = String::from_utf8_lossy(&body_bytes);
            println!("ğŸ” Response status: {}", parts.status);
            println!("ğŸ” Response body: {}", body_str);
        }

        assert_eq!(parts.status, StatusCode::OK);
        let body_str = String::from_utf8_lossy(&body_bytes);

        // éªŒè¯å“åº”æ˜¯BatchCdnUrlResponseæ ¼å¼
        let json_response: serde_json::Value = serde_json::from_str(&body_str).unwrap();
        assert!(json_response.get("urls").is_some(), "å“åº”åº”è¯¥åŒ…å«urlså­—æ®µ");

        let urls = json_response.get("urls").unwrap().as_object().unwrap();
        assert_eq!(urls.len(), 3, "åº”è¯¥åŒ…å«3ä¸ªchunkçš„ç»“æœ");

        // éªŒè¯æ¯ä¸ªchunkéƒ½æœ‰urlå­—æ®µï¼ˆæ ¹æ®mockå®ç°ï¼‰
        for chunk_id in &["0-1023", "1024-2047", "2048-4095"] {
            assert!(urls.contains_key(*chunk_id), "åº”è¯¥åŒ…å«chunk: {}", chunk_id);
            let chunk_result = urls.get(*chunk_id).unwrap();
            // ç”±äºmockå®ç°ä¸­Flowä¼šç”ŸæˆURLï¼Œåº”è¯¥æœ‰urlå­—æ®µ
            assert!(
                chunk_result.get("url").is_some() || chunk_result.get("error").is_some(),
                "chunkç»“æœåº”è¯¥åŒ…å«urlæˆ–errorå­—æ®µ"
            );
        }

        println!("âœ… POST batch CDN success test completed!");
    }

    #[tokio::test]
    async fn test_post_batch_cdn_empty_chunks() {
        let env = TestEnvironment::new().await;

        let session_id = "test_batch_session_empty";
        let session = SessionBuilder::new()
            .with_resource_id("test_resource")
            .with_chunks(vec!["0-1023"])
            .build();

        env.services
            .session_service
            .store_session(session_id, &session)
            .await
            .unwrap();

        // æ„é€ ç©ºchunksè¯·æ±‚
        let request_body = crate::models::BatchChunkRequest { chunks: vec![] };

        let headers = HeaderMap::new();
        let real_connect_info = RealConnectInfo::from_headers_and_addr(
            &HeaderMap::new(),
            "127.0.0.1:8080".parse().unwrap(),
        );

        // è°ƒç”¨æ‰¹é‡CDN API
        let response = post_batch_cdn(
            Extension(env.app_context.clone()),
            Extension(real_connect_info),
            headers,
            Path((session_id.to_string(), "test_resource".to_string())),
            axum::Json(request_body),
        )
        .await;

        // éªŒè¯å“åº” - åº”è¯¥è¿”å›400é”™è¯¯
        assert!(response.is_err(), "ç©ºchunksæ•°ç»„åº”è¯¥è¿”å›é”™è¯¯");

        // éªŒè¯é”™è¯¯ç±»å‹
        let error = response.unwrap_err();
        assert!(error.to_string().contains("Chunks array cannot be empty"));

        println!("âœ… POST batch CDN empty chunks test completed!");
    }

    #[tokio::test]
    async fn test_post_batch_cdn_session_not_found() {
        let env = TestEnvironment::new().await;

        let request_body = crate::models::BatchChunkRequest {
            chunks: vec!["0-1023".to_string()],
        };

        let headers = HeaderMap::new();
        let real_connect_info = RealConnectInfo::from_headers_and_addr(
            &HeaderMap::new(),
            "127.0.0.1:8080".parse().unwrap(),
        );

        // ä½¿ç”¨ä¸å­˜åœ¨çš„session ID
        let response = post_batch_cdn(
            Extension(env.app_context.clone()),
            Extension(real_connect_info),
            headers,
            Path((
                "nonexistent_session".to_string(),
                "test_resource".to_string(),
            )),
            axum::Json(request_body),
        )
        .await;

        // éªŒè¯å“åº” - åº”è¯¥è¿”å›session not foundé”™è¯¯
        assert!(response.is_err(), "ä¸å­˜åœ¨çš„sessionåº”è¯¥è¿”å›é”™è¯¯");

        println!("âœ… POST batch CDN session not found test completed!");
    }

    #[tokio::test]
    async fn test_post_batch_cdn_resource_not_found() {
        let env = TestEnvironment::new().await;

        let session_id = "test_batch_session_no_resource";
        let session = SessionBuilder::new()
            .with_resource_id("nonexistent_resource") // ä¸å­˜åœ¨çš„èµ„æº
            .with_chunks(vec!["0-1023"])
            .build();

        env.services
            .session_service
            .store_session(session_id, &session)
            .await
            .unwrap();

        let request_body = crate::models::BatchChunkRequest {
            chunks: vec!["0-1023".to_string()],
        };

        let headers = HeaderMap::new();
        let real_connect_info = RealConnectInfo::from_headers_and_addr(
            &HeaderMap::new(),
            "127.0.0.1:8080".parse().unwrap(),
        );

        // è°ƒç”¨æ‰¹é‡CDN API
        let response = post_batch_cdn(
            Extension(env.app_context.clone()),
            Extension(real_connect_info),
            headers,
            Path((session_id.to_string(), "nonexistent_resource".to_string())),
            axum::Json(request_body),
        )
        .await;

        // éªŒè¯å“åº” - åº”è¯¥è¿”å›resource not foundé”™è¯¯
        assert!(response.is_err(), "ä¸å­˜åœ¨çš„èµ„æºåº”è¯¥è¿”å›é”™è¯¯");

        let error = response.unwrap_err();
        assert!(error.to_string().contains("not found") || error.to_string().contains("Resource"));

        println!("âœ… POST batch CDN resource not found test completed!");
    }

    #[tokio::test]
    async fn test_post_batch_cdn_data_flow_verification() {
        let env = TestEnvironment::new().await;

        let session_id = "test_batch_data_flow";
        let session = SessionBuilder::new()
            .with_resource_id("test_resource")
            .with_chunks(vec!["0-1023", "1024-2047"])
            .build();

        env.services
            .session_service
            .store_session(session_id, &session)
            .await
            .unwrap();

        let request_body = crate::models::BatchChunkRequest {
            chunks: vec!["0-1023".to_string(), "1024-2047".to_string()],
        };

        let headers = HeaderMap::new();
        let real_connect_info = RealConnectInfo::from_headers_and_addr(
            &HeaderMap::new(),
            "127.0.0.1:8080".parse().unwrap(),
        );

        // è°ƒç”¨æ‰¹é‡CDN API
        let response = post_batch_cdn(
            Extension(env.app_context.clone()),
            Extension(real_connect_info),
            headers,
            Path((session_id.to_string(), "test_resource".to_string())),
            axum::Json(request_body),
        )
        .await;

        // éªŒè¯åŸºæœ¬å“åº”
        assert!(response.is_ok(), "APIåº”è¯¥æˆåŠŸå“åº”");

        let api_response = response.unwrap();
        let response = axum::response::IntoResponse::into_response(api_response);
        let (parts, body) = response.into_parts();
        assert_eq!(parts.status, StatusCode::OK);

        // éªŒè¯æ•°æ®æµï¼šæ‰¹é‡æ“ä½œåº”è¯¥è¢«è°ƒç”¨
        // è¿™é‡Œæˆ‘ä»¬é€šè¿‡MockDataStoreçš„è¡Œä¸ºæ¥éªŒè¯
        // åœ¨å®é™…åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ‰©å±•MockDataStoreæ¥è®°å½•è°ƒç”¨å†å²

        let body_bytes = axum::body::to_bytes(body, usize::MAX).await.unwrap();
        let body_str = String::from_utf8_lossy(&body_bytes);
        let json_response: serde_json::Value = serde_json::from_str(&body_str).unwrap();

        let urls = json_response.get("urls").unwrap().as_object().unwrap();
        assert_eq!(urls.len(), 2, "åº”è¯¥å¤„ç†2ä¸ªchunk");

        // éªŒè¯å¹¶å‘é™åˆ¶ï¼šè™½ç„¶æˆ‘ä»¬æ— æ³•ç›´æ¥æµ‹è¯•ä¿¡å·é‡ï¼Œä½†å¯ä»¥éªŒè¯æ‰€æœ‰chunkéƒ½è¢«å¤„ç†
        assert!(urls.contains_key("0-1023"));
        assert!(urls.contains_key("1024-2047"));

        println!("âœ… POST batch CDN data flow verification test completed!");
    }

    #[tokio::test]
    async fn test_post_batch_cdn_error_chunk_id_preservation() {
        println!("ğŸ§ª Testing batch CDN error chunk_id preservation...");

        let env = TestEnvironment::new().await;

        // åˆ›å»ºsessionï¼ˆæœ‰æ•ˆçš„chunkå’Œæ— æ•ˆçš„chunkæ··åˆï¼‰
        let session_id = "test_error_session";
        let session = SessionBuilder::new()
            .with_resource_id("test_resource")
            .with_version("1.0.0")
            .with_chunks(vec!["0-1023", "1024-2047"]) // åªæœ‰è¿™ä¸¤ä¸ªchunkæ˜¯æœ‰æ•ˆçš„
            .build();

        env.services
            .session_service
            .store_session(session_id, &session)
            .await
            .unwrap();

        // å‡†å¤‡åŒ…å«æ— æ•ˆchunkçš„è¯·æ±‚
        let request_body = crate::models::BatchChunkRequest {
            chunks: vec![
                "0-1023".to_string(),     // æœ‰æ•ˆchunk
                "9999-10000".to_string(), // æ— æ•ˆchunk (ä¸åœ¨session.chunksä¸­)
                "1024-2047".to_string(),  // æœ‰æ•ˆchunk
                "invalid-format".to_string(), // æ ¼å¼æ— æ•ˆçš„chunk
            ],
        };

        // æ¨¡æ‹ŸHTTPè¯·æ±‚å…ƒæ•°æ®
        let real_connect_info = RealConnectInfo {
            remote_addr: "192.168.1.100:8080".parse().unwrap(),
        };
        let headers = HeaderMap::new();

        // è°ƒç”¨æ‰¹é‡CDN API
        let response = post_batch_cdn(
            Extension(env.app_context.clone()),
            Extension(real_connect_info),
            headers,
            Path((session_id.to_string(), "test_resource".to_string())),
            axum::Json(request_body),
        )
        .await;

        // éªŒè¯å“åº”
        assert!(response.is_ok(), "APIåº”è¯¥æˆåŠŸå“åº”");

        let api_response = response.unwrap();
        let response = axum::response::IntoResponse::into_response(api_response);
        let (parts, body) = response.into_parts();

        assert_eq!(parts.status, StatusCode::OK);

        let body_bytes = axum::body::to_bytes(body, usize::MAX).await.unwrap();
        let body_str = String::from_utf8_lossy(&body_bytes);
        let json_response: serde_json::Value = serde_json::from_str(&body_str).unwrap();

        let urls = json_response.get("urls").unwrap().as_object().unwrap();
        
        // éªŒè¯æ‰€æœ‰chunkéƒ½æœ‰å¯¹åº”çš„ç»“æœï¼ŒåŒ…æ‹¬é”™è¯¯çš„chunk
        assert_eq!(urls.len(), 4, "åº”è¯¥è¿”å›æ‰€æœ‰4ä¸ªchunkçš„ç»“æœ");
        
        // éªŒè¯æˆåŠŸçš„chunkè¿”å›æ­£ç¡®çš„chunk_id
        assert!(urls.contains_key("0-1023"), "åº”è¯¥åŒ…å«æœ‰æ•ˆchunk 0-1023");
        assert!(urls.contains_key("1024-2047"), "åº”è¯¥åŒ…å«æœ‰æ•ˆchunk 1024-2047");
        
        // éªŒè¯å¤±è´¥çš„chunkè¿”å›åŸå§‹chunk_idè€Œä¸æ˜¯è™šå‡çš„"error_chunk"æˆ–"unknown_chunk"
        assert!(urls.contains_key("9999-10000"), "åº”è¯¥åŒ…å«chunk 9999-10000");
        assert!(urls.contains_key("invalid-format"), "åº”è¯¥åŒ…å«å¤±è´¥çš„chunk invalid-format");
        
        // æ³¨æ„ï¼š9999-10000åœ¨MockDataStoreä¸­è¢«å¤„ç†ä¸ºæœ‰æ•ˆï¼ˆè¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºmockæ²¡æœ‰å®Œå…¨æ¨¡æ‹Ÿæ‰€æœ‰éªŒè¯ï¼‰
        // é‡ç‚¹æ˜¯éªŒè¯å®ƒè¿”å›äº†æ­£ç¡®çš„chunk_idè€Œä¸æ˜¯"error_chunk"
        let chunk_9999_result = urls.get("9999-10000").unwrap();
        // è¿™ä¸ªchunkåœ¨mockç¯å¢ƒä¸­æˆåŠŸäº†ï¼Œæ‰€ä»¥æœ‰URL
        assert!(chunk_9999_result.get("url").is_some(), "chunk 9999-10000åœ¨mockç¯å¢ƒä¸­åº”è¯¥æœ‰urlå­—æ®µ");
        
        // invalid-formatæ˜¯çœŸæ­£æ ¼å¼é”™è¯¯çš„chunkï¼Œåº”è¯¥æœ‰error
        let malformed_chunk_result = urls.get("invalid-format").unwrap();
        assert!(malformed_chunk_result.get("error").is_some(), "æ ¼å¼é”™è¯¯çš„chunkåº”è¯¥æœ‰errorå­—æ®µ");
        assert!(malformed_chunk_result.get("url").is_none() || malformed_chunk_result.get("url").unwrap().is_null(), "æ ¼å¼é”™è¯¯çš„chunkä¸åº”è¯¥æœ‰urlå­—æ®µ");
        
        // éªŒè¯æˆåŠŸçš„chunkæœ‰urlå­—æ®µè€Œæ²¡æœ‰errorå­—æ®µ
        let success_chunk_result = urls.get("0-1023").unwrap();
        assert!(success_chunk_result.get("url").is_some(), "æˆåŠŸçš„chunkåº”è¯¥æœ‰urlå­—æ®µ");
        assert!(success_chunk_result.get("error").is_none() || success_chunk_result.get("error").unwrap().is_null(), "æˆåŠŸçš„chunkä¸åº”è¯¥æœ‰errorå­—æ®µ");

        println!("âœ… POST batch CDN error chunk_id preservation test completed!");
        println!("   - æ‰€æœ‰chunkéƒ½æ­£ç¡®è¿”å›åŸå§‹chunk_idï¼ŒåŒ…æ‹¬ï¼š");
        println!("     * æˆåŠŸçš„chunk: 0-1023, 1024-2047, 9999-10000 (æœ‰urlå­—æ®µ)");
        println!("     * å¤±è´¥çš„chunk: invalid-format (æœ‰errorå­—æ®µ)");
        println!("   - ä¿®å¤éªŒè¯ï¼šä¸å†ä½¿ç”¨è™šå‡çš„'error_chunk'æˆ–'unknown_chunk'ä½œä¸ºkey");
    }
}
